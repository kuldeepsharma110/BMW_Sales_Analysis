# -*- coding: utf-8 -*-
"""BMW_car_sales_volume_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g6xytgkPlbVl9IoSRrHhRbOVc1VCJtoD

# **Importing Data from kaggle**
"""

# fetching data from kaggle
import kagglehub
from IPython.display import display

# Download latest version
dir_path = kagglehub.dataset_download("ahmadrazakashif/bmw-worldwide-sales-records-20102024")

print("Path to dataset files:", dir_path)

import os
for file in os.listdir(dir_path):
  print(file)

# joining directory and file path
file_path = os.path.join(dir_path,file)

"""# Importing necessary Libraries"""

# importing necessary libraries
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

"""# **Dataset Overview**"""

df = pd.read_csv(file_path)
df.head()

display(df.head())
display(df.tail())
display(df.info())
display(df.describe())
print(f"shape of data is {df.shape}")

"""## **Insight**

1. Dataset is having 50,000 rows and 11 columns
2. There is no null value as null value count in all rows is 50,000.
3. Categorical data is in object and numerical data is in int and float so there is no need for dtype conversion
4.  There are 5 numerical columns

* From year column it is clear that data is from 2010 to 2024
* engine size is from 1.5l to 5l.
* non of BMW car sale is greater than 9999 in any year and least sale is of 100 units only.

# **Data Validation**

1. check null values
2. duplicate values
3. check datatypes
4. check required data as per objective(ex we are doing minute wise analysis and and data of certain time is missing.)
5. check value in each column (ex age can't be negative)
"""

# check duplicate values present in dataset
df.duplicated().sum()

# check data set values if they require correction
for i in df.columns:
  print(sorted(df[i].unique()))

# seperating numerical column and catagorical column
cat_column=[]
num_column=[]
for i in df.columns:
  if df[i].dtype == object:
    cat_column.append(i)
  else:
    num_column.append(i)

print(f"categorical columns are {cat_column}")
print(f"Numerical columns are {num_column}")

# checking numerical values they are negative or not as in the dataset negative value doesnot make sense

for i in num_column:
  sns.histplot(df,x=i, bins=5)
  plt.show()

# checking outlier in my dataset
for i in num_column:
  sns.boxplot(df,x=i)
  plt.show()

"""## **Insights**

1. There is no duplicated values in the dataset.
2. All the values in the catagorical column are in proper format.
3. All numerical values are positive.
4. Their is no outlier in the numerical data seen from box plot.

# Feature Engineering
**From the above analysis it is seen that mileage column has no relatonship with the other columns due to this we will drop this column**
"""

df=df.drop(columns=['Mileage_KM'])

#display(df)

"""# **Now my data is ready for Analysis**

# Univariate analysis

# catagorical columns
"""

for i in cat_column:
  #df[i].value_counts().plot(kind="bar",label=True)

  ax=sns.countplot(x=df[i])
  for cont in ax.containers:
      ax.bar_label(cont)
  plt.tight_layout()
  plt.show()

for i in cat_column:
  df[i].value_counts().plot(kind="pie",autopct="%.2f")

  # ax=sns.countplot(x=df[i])
  # for cont in ax.containers:
  #     ax.bar_label(cont)
  plt.tight_layout()
  plt.show()

"""## Insight
1. Dataset is uniformly distributed based on all the categorical columns.

# Univarite analysis on numerical columns
"""

for i in num_column:
  try:
    sns.kdeplot(x=df[i])
    plt.show()
  except Exception as e:
    print(e)

"""##**Insight**
1. We have choosen kde plot to check the density of value in particular region.
2. It is showing uniform distribution for all the numerical column.

# Bivariate and Multivariate analysis

## model vs sales
"""

df.groupby("Model").agg({"Sales_Volume":"mean"})

plt.figure(figsize=(15,5))
ax=sns.barplot(df,x="Model",y="Sales_Volume",estimator=sum,ci=None)

for con in ax.containers:
  ax.bar_label(con)
plt.tight_layout()
plt.show()

"""**Insight**

1. **Across all year sale is approxmitaly same for all models.**
"""

plt.figure(figsize=(25,10))
ax=sns.barplot(df,x="Model",y="Sales_Volume",estimator=np.average,ci=None,hue="Transmission")

"""**Insight**
1. Demand for automatic and manual transmission is same in all models

## check year wise trend of sales volume
"""

sns.lineplot(df, x="Year",y="Sales_Volume", estimator=sum, ci=None)
plt.show()

"""**Insights**

1. There is too much fluctuation after 2018 in sales volume.
2. In 2022 sales is max.

## Region wise sales.
"""

df_region=df.groupby("Region").agg({"Sales_Volume":"sum"}).reset_index()
# region_df.ndim
display(df_region)
plt.pie(x=df_region["Sales_Volume"],labels=df_region["Region"],autopct="%.2f")

"""## **Sales_Volume is same across all region. We are choosing Asia for our analysis because it is our continent.**"""

df.columns

asia_df=df[df["Region"]=="Asia"].sort_values(by="Sales_Volume",ascending=False)
display(asia_df)

"""**which model has lowest sales volume in asia**"""

sns.barplot(asia_df.groupby("Model").agg({"Sales_Volume":"sum"}).reset_index().sort_values(by = "Sales_Volume",ascending=False), x="Model", y="Sales_Volume",estimator="sum")

# i3 model is have less sales volume.
asia_i3_df=asia_df[asia_df["Model"]=="i3"]
display(asia_i3_df)

"""## year wise trend of i3 model"""

sns.lineplot(asia_i3_df,x="Year",y="Sales_Volume",ci=None)

"""* Critical sales volume is around 5200.

## year wise trend of i3 model wrt color
"""

plt.figure(figsize=(15,5))
sns.lineplot(asia_i3_df,x="Year",y="Sales_Volume",ci=None,hue="Color", hue_order=["Blue","Black","White","Red","Grey","Silver"])

"""**In 2010, 2015,2021 Black or grey colour shows high sales volume. These colour have the potential to attract more customer in future.**

## year wise trend of i3 model wrt transmission
"""

plt.figure(figsize=(15,5))
sns.lineplot(asia_i3_df,x="Year",y="Sales_Volume",ci=None,hue="Transmission")

"""**Sales volume of i3 model with manual transmission is a constant range 4800 to 5700. On the other hand automatic transmission sales volume is unpredictable some time it is  high Than 6000 and some time low than 3200.**"""

# year wise trend of i3 model wrt Fuel type
plt.figure(figsize=(15,5))
sns.lineplot(asia_i3_df,x="Year",y="Sales_Volume",ci=None,hue="Fuel_Type")

"""1. Petrol sales volume is low in last 4 year.
2. Electric,desiel car performace is constant.
3. Hybrid car prediction is unpredicted.

# engine_size analysis, year wise trend of i3 model
"""

plt.figure(figsize=(15,5))
sns.lineplot(asia_i3_df[asia_i3_df["Fuel_Type"]=="Hybrid"],x="Year",y="Sales_Volume",ci=None,hue="Engine_Size_L")

df["Engine_Size_L"].unique()

# there is too much engine value we will categories them
# if size is less than 1.5 then small engine, if size is between 1.5 to 3 mid size engine , if size greater than 3 big engine.
import numpy as np

# Define conditions
conditions = [
    asia_i3_df["Engine_Size_L"] < 1.5,
    (asia_i3_df["Engine_Size_L"] >= 1.5) & (asia_i3_df["Engine_Size_L"] <= 3),
    asia_i3_df["Engine_Size_L"] > 3
]

# Define corresponding categories
choices = ["small engine", "mid size engine", "big engine"]

# Apply to DataFrame
asia_i3_df["engine_category"] = np.select(conditions, choices, default="unknown")

asia_i3_df["engine_category"].unique()

asia_i3_df

plt.figure(figsize=(15,5))
sns.lineplot(asia_i3_df[asia_i3_df["Fuel_Type"]=="Hybrid"],x="Year",y="Sales_Volume",ci=None,hue="engine_category")

"""**Mid size engine demand is increased after 2021 and big size engine demand is almost constant.**

# Findings

1. Sales Volume is approximately same is all region.
2. In Asia i3 model has lowest sale.
3. In i3 model in 2010, 2015,2021 Black or grey colour shows high sales volume. These colour have the potential to attract more customer in future.
4. Sales volume of i3 model with manual transmission is a constant range 4800 to 5700. On the other hand automatic transmission sales volume is unpredictable some time it is  high Than 6000 and some time low than 3200.
5. Petrol sales volume is low in last 4 year.
6. Electric,desiel car performace is constant.
7. Hybrid car prediction is unpredicted.

# **Conclusion**

**To boost sales of the BMW i3 model, the company should focus on producing black or grey cars with manual transmission and mid-size engines, while avoiding petrol variants due to their declining demand trend.**
"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score,mean_absolute_percentage_error
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer

#display(asia_df)

len(asia_df["Model"].unique())

len(asia_df["Region"].unique())

len(asia_df["Color"].unique())

len(asia_df["Fuel_Type"].unique())

len(asia_df["Transmission"].unique())

# X=asia_df[["Model","Year","Color","Fuel_Type","Transmission","Engine_Size_L","Price_USD"]]
# y=asia_df[["Sales_Volume"]]

# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)

# transformer=ColumnTransformer(transformers=[("tnf",OneHotEncoder(sparse_output=False,drop='first'),["Model","Color","Fuel_Type","Transmission"])],remainder='passthrough')

# transformer

# X_train_new = pd.DataFrame(transformer.fit_transform(X_train))
# X_train_new = X_train_new.iloc[:, :-1]
# # X_train_new.head()

# # X_train_new=transformer.fit_transform(X_train)

# X_train_new.shape

# X_test_new=pd.DataFrame(transformer.transform(X_test))
# X_test_new = X_test_new.iloc[:, : - 1]

# X_test_new.head()

# model= LinearRegression()

# # Fit the Algorithm
# model.fit(X_train_new, y_train)

# # Predict on the model
# y_pred = model.predict(X_test_new)

# # Calculate RÂ² (Coefficient of Determination)
# r2 = r2_score(y_test, y_pred)
# print(f"R-Squared: {r2}")

# mse = mean_squared_error(y_test, y_pred)
# print("Mean Squared Error:", mse)

# for i in range(y_pred.shape[0]):
#     print(y_test.iloc[i], " == ", y_pred[i])
#     if i == 10:
#         break

new_one = OneHotEncoder()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import r2_score, mean_absolute_error

# Load your dataset
# df = pd.read_csv(".csv")  # Replace with actual filename

# Drop unnecessary columns
df = df.drop(columns=["Price_USD", "Mileage_KM", "Sales_Classification"], errors='ignore')

# Define target variable
y = df["Sales_Volume"]

# Feature set
X = df.drop(columns=["Sales_Volume"])

# Identify categorical and numeric columns
cat_cols = ["Model", "Color", "Fuel_Type", "Transmission", "Region"]
num_cols = ["Year", "Engine_Size_L"]

# Preprocessing pipeline
preprocess = ColumnTransformer(
    transformers=[
        ("cat", OneHotEncoder(drop="first", sparse_output=False), cat_cols)
    ],
    remainder="passthrough"
)

# Complete pipeline
model = Pipeline(steps=[
    ("preprocess", preprocess),
    ("regressor", LinearRegression())
])

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train model
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)

# Evaluation
print("R2 Score:", r2_score(y_test, y_pred))
print("MAE:", mean_absolute_error(y_test, y_pred))

mean_squared_error(y_test, y_pred)

import joblib

# Save the model
joblib.dump(model, "model.pkl")

# Load the model
model_loaded = joblib.load("model.pkl")